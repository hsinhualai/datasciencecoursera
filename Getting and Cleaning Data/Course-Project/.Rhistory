m$getmean()
cachemean(m)
m$getmean()
cachemean(m)
m$set(c(10,20,30,50))
m$getmean()
cachemean(m)
cachemean(m)
m$get()
m$setmean()
m$getmean()
makeVector(c(1,2,3,4))
a <- makeVector(c(1,2,3,4))
a
a$get()
a$getmean
a$getmean()
cachemean(a)
a$getmean()
a$getmean()
cachemean(a)
a$set(c(100,200))
cachemean(a)
a$getmean()
q()
install.packages("swirl")
evaluate <- function(func, dat){
func_sum    <- function(dat) {sum(dat)}
func_meidan <- function(dat) {median(dat)}
func_floor  <- function(dat) {floor(dat)}
a <- func(dat)
return(a)
}
evaluate(sd, c(1,2,3))
evaluate(sd, c(1,2,5))
evaluate(sum, c(1,2,5))
evaluate <- function(func, dat){
func_fun    <- function(dat) {fun(dat)}
a <- func(dat)
return(a)
}
evaluate(sum,c(1,2,5))
evaluate(sum,c(1,2,9))
evaluate <- function(func, dat){
func_fun    <- function(dat) {dat}
a <- func(dat)
return(a)
}
evaluate(sum,c(1,2,9))
evaluate <- function(func, dat){
func_fun    <- function(dat) {print(dat)}
a <- func(dat)
return(a)
}
evaluate(a, c(1,1,1))
evaluate <- function(func, dat){
#       func_fun    <- function(dat) {print(dat)}
a <- func(dat)
return(a)
}
evaluate(sum, c(1,1,1))
evaluate(sum, c(1,1,10))
evaluate(sd, c(1,1,10))
evaluate <- function(func, dat){
a <- func(dat)
return(a)
}
evaluate(median, c(1,5,10))
evaluate(length, c(1,5,10))
evaluate <- function(func, dat){
a <- func(dat)
return(a)
}
x <- matrix(1:6, 2, 2)
x
x <- matrix(1:6, 2, 3)
x
evaluate(colMeans,x)
evaluate(colSums,x)
q()
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
makeCacheMatrix <- function(x = matrix()) {
x <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setsolve <- function(solve) m <<- solve
getsolve <- function() m
list(set = set, get = get,
setsolve = setsolve,
getsolve = getsolve)
}
makeCacheMatrix <- function(x = matrix()) {
x <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setsolve <- function(solve) m <<- solve
getsolve <- function() m
list(set = set, get = get,
setsolve = setsolve,
getsolve = getsolve)
}
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
m <- x$getsolve()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data, ...)
x$setsolve(m)
m
}
a <- matrix(1:4, 2,2)
dat <- makeCacheMatrix(a)
cacheSolve(dat)
makeCacheMatrix <- function(x = matrix()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setsolve <- function(solve) m <<- solve
getsolve <- function() m
list(set = set, get = get,
setsolve = setsolve,
getsolve = getsolve)
}
cacheSolve(dat)
dat <- makeCacheMatrix(a)
cacheSolve(dat)
cacheSolve(dat)
dat$getsolve()
dat_inverse <- dat$getsolve()
dat_inverse * dat
dat_inverse . dat
dat_iverse %*% dat
dat_inverse %*% dat
dat_inverse
class(dat_inverse)
class(dat)
dat
dat$get()
dat
dat_inverse %*% a
a
dat
q()
install.packages("RMySQL")
q()
q()
library(nycflights13)
library(nycflights13)
install.packages("nycflights13")
library(nycflights13)
dim(flights)
names(flights)
select(flights, year, month, day)
library(dplyr)
library(dplyr)
install.packages("dplyr")
select(flights, year, month, day)
library(dplyr)
select(flights, year, month, day)
filter(flights, month ==1 | month ==2)
filter(flights, month ==1 & month ==2)
filter(flights, month ==1)
filter(flights, month == 2)
filter(flights, month == 1 & day == 10)
filter(flights, month == 2 & day == 10)
select(flights, year, month, day, dep_time)
q()
install.packages("xlsx")
install.packages("numbers")
q()
library(jsonlite)
library(data.table)
install.packages("data.table")
library(data.table)
DF = data.frame(x = rnorm(9), y = rep(c("a", "b", "c"), each=3), z = rnorm(9))
head(DF, 3)
DT = data.table(x = rnorm(9), y = rep(c("a", "b", "c"), each=3), z = rnorm(9))
head(DT,3)
tables()
DT[2,]
DT[DT$y == "a",]
DT[c(2,3),]
DT[,c(2,3)]
DT[, list(mean(x), sum(z))]
DT[, table(y)]
DT[, w:z^2]
DT[, w:=z^2]
Dt
DT
DT2 <- DT
DT[, y:=2]
DT[, y:= 2]
DT
head(DT, n=2)
head(DT, n=3)
head(DT2, n=3)
DT[, m:={tmp <- (x+z); log2(tmp +5)}]
DT
DT[, a:= x>0]
DT
DT[, b:= mean(x+w), by = a]
DT
set.seed(123)
DT <- data.table(x = samply(letters[1:3], 1e5, TRUE))
DT <- data.table(x = sample(letters[1:3], 1e5, TRUE))
DT, .N, by=x
DT[], .N, by=x]
DT[, .N, by=x]
DT <- data.table(x = rep(c("a", "b", "c"), each = 100), y = rnorm(300))
setkey(DT,x)
DT['a']
DT['b']
DT['c']
DT['a']
DT1 <- data.table( x = c('a', 'a', 'b', 'dt1'), y = 1:4)
DT2 <- data.table( x=c('a', 'b', 'dt2'), z = 5:7)
setkey(DT1, x); seteky(DT2, x)
setkey(DT1, x); setkey(DT2, x)
DT1
DT2
merge(DT1, DT2)
q()
install.packages("XML")
q()
install.packages("httr")
library(jsonlite)
install.packages("httpuv")
library(httpuv)
library(httr)
install.packages("sqldf")
install.packages("RMySQL")
library(RMySQL)
install.packages("DBI")
library(RMySQL)
library(DBI)
library(RMySQL)
install.packages("fortran")
install.packages("foreign")
q()
library(jpeg)
install.packages("jpeg")
library(dplyr)
q()
install.packages("quantmod")
q()
swirl()
library(swirl)
swirl()
View(top_counts)
pack_sum
arrange(top_counts, desc(count))
pack_sum
top_counts <- filter(pack_sum, count > 679)
arrange(top_counts, desc(count))
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum, unique, probs = 0,99)
quantile(pack_sum$unique, probs = 0,99)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_uniquw)
View(top_unique)
arrange(top_unique, desc(unique)
)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique, sorted)
View(top_unique_sorted)
submit()
submit()
submit()
View(pack_sum)
View(result3)
submit()
submit()
submit()
submit()
q()
df <- data.frame(x = c("a", "b"), y = c(3, 4), z = c(5, 6))
df %>% spread(x, y) %>% gather(x, y, a:b, na.rm = TRUE)
library(dplyr)
df %>% spread(x, y) %>% gather(x, y, a:b, na.rm = TRUE)
library(tidyr)
df %>% spread(x, y) %>% gather(x, y, a:b, na.rm = TRUE)
df
df <- data.frame(x = c("a", "b"), y = c(3, 4), z = c(5, 6))
df
df %>% spread(x, y) %>% gather(x, y, a:b, na.rm = TRUE)
df %>% spread(x,y)
data(mtcars)
mtcars
mutate(mtcars, disp = -disp)
mtcars
mutate(mtcars, mpg = - mpg)
mtcars
mutate(mtcars, test = extract_numeric(mpg))
mutate(mtcars, mpg = extract_numeric(mpg))
## Create one R script called run_analysis.R that does the following:
## 1. Merges the training and the test sets to create one data set.
## 2. Extracts only the measurements on the mean and standard deviation for each measurement.
## 3. Uses descriptive activity names to name the activities in the data set
## 4. Appropriately labels the data set with descriptive activity names.
## 5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
setwd("/Users/hsinhua/Desktop/Coursera/Getting and Cleaning Data/Course-Project")
if (!require("data.table")) {
install.packages("data.table")
}
if (!require("reshape2")) {
install.packages("reshape2")
}
require("data.table")
require("reshape2")
# Load: activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
# Load: data column names
features <- read.table("./UCI HAR Dataset/features.txt")[,2]
# Extract only the measurements on the mean and standard deviation for each measurement.
extract_features <- grepl("mean|std", features)
# Load and process X_test & y_test data.
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
names(X_test) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_test = X_test[,extract_features]
# Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) = c("Activity_ID", "Activity_Label")
names(subject_test) = "subject"
# Bind data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
# Load and process X_train & y_train data.
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
names(X_train) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,extract_features]
# Load activity data
y_train[,2] = activity_labels[y_train[,1]]
names(y_train) = c("Activity_ID", "Activity_Label")
names(subject_train) = "subject"
# Bind data
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
# Merge test and train data
data = rbind(test_data, train_data)
id_labels   = c("subject", "Activity_ID", "Activity_Label")
data_labels = setdiff(colnames(data), id_labels)
melt_data      = melt(data, id = id_labels, measure.vars = data_labels)
# Apply mean function to dataset using dcast function
tidy_data   = dcast(melt_data, subject + Activity_Label ~ variable)
write.table(tidy_data, file = "./tidy_data.txt")
## Create one R script called run_analysis.R that does the following:
## 1. Merges the training and the test sets to create one data set.
## 2. Extracts only the measurements on the mean and standard deviation for each measurement.
## 3. Uses descriptive activity names to name the activities in the data set
## 4. Appropriately labels the data set with descriptive activity names.
## 5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
setwd("/Users/hsinhua/Desktop/Coursera/Getting and Cleaning Data/Course-Project")
if (!require("data.table")) {
install.packages("data.table")
}
if (!require("reshape2")) {
install.packages("reshape2")
}
require("data.table")
require("reshape2")
# Load: activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
# Load: data column names
features <- read.table("./UCI HAR Dataset/features.txt")[,2]
# Extract only the measurements on the mean and standard deviation for each measurement.
extract_features <- grepl("mean|std", features)
# Load and process X_test & y_test data.
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
names(X_test) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_test = X_test[,extract_features]
# Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) = c("Activity_ID", "Activity_Label")
names(subject_test) = "subject"
# Bind data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
# Load and process X_train & y_train data.
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
names(X_train) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,extract_features]
# Load activity data
y_train[,2] = activity_labels[y_train[,1]]
names(y_train) = c("Activity_ID", "Activity_Label")
names(subject_train) = "subject"
# Bind data
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
# Merge test and train data
data = rbind(test_data, train_data)
id_labels   = c("subject", "Activity_ID", "Activity_Label")
data_labels = setdiff(colnames(data), id_labels)
melt_data      = melt(data, id = id_labels, measure.vars = data_labels)
# Apply mean function to dataset using dcast function
tidy_data   = dcast(melt_data, subject + Activity_Label ~ variable, mean)
write.table(tidy_data, file = "./tidy_data.txt")
## Create one R script called run_analysis.R that does the following:
## 1. Merges the training and the test sets to create one data set.
## 2. Extracts only the measurements on the mean and standard deviation for each measurement.
## 3. Uses descriptive activity names to name the activities in the data set
## 4. Appropriately labels the data set with descriptive activity names.
## 5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
setwd("/Users/hsinhua/Desktop/Coursera/Getting and Cleaning Data/Course-Project")
if (!require("data.table")) {
install.packages("data.table")
}
if (!require("reshape2")) {
install.packages("reshape2")
}
library("data.table")
library("reshape2")
## Let's first read the data in the test foler
## Import the subject IDs for tests
subject_testID <- read.table("./UCI HAR Dataset/test/subject_test.txt")
## Import the test results
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
## Import the activity test for each test subject labeled from 1 - 6
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt")[,1]
## Now in order to make tidy data, we need the "column names"
## The column names for test results are given in features.txt
## Import features as the column names for the test results data
features <- read.table("./UCI HAR Dataset/features.txt")[,2]
## Now let's assign the "column names" to the test results
names(X_test) <- features
## We prefer the activity names instead of the number label
## We reexpress y_test in terms of actual activity names
## Import the activity label
Act_Label <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
## Nowe we have the activity labels as a list
## We rewrite y_test
y_test <- as.data.frame(Act_Label[y_test])
## Now we assign column names for subject_testID and y_test
names(subject_testID) <- "ID"
names(y_test) <- "Activity"
## Let's column combine the ID column, Activity column, and all feature columns
test_data <- cbind(subject_testID, y_test, X_test)
## Now we simply repeat the same procedue to construct the train_data
## Import the subject IDs for trains
subject_trainID <- read.table("./UCI HAR Dataset/train/subject_train.txt")
## Import the training results
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
## Import the activity test for each train subject labeled from 1 - 6
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt")[,1]
## Now in order to make tidy data, we need the "column names"
## The column names for train results are given in features.txt
## Now let's assign the "column names" to the train results
names(X_train) <- features
## We prefer the activity names instead of the number label
## We rewrite y_train
y_train <- as.data.frame(Act_Label[y_train])
## Now we assign column names for subject_trainID and y_train
names(subject_trainID) <- "ID"
names(y_train) <- "Activity"
## Note that for train and test data have the same column names
## Let's column combine the ID column, Activity column, and all feature columns
train_data <- cbind(subject_trainID, y_train, X_train)
## Now let's row combine test_data and train data
data <- rbind(test_data, train_data)
## Now we select the columns we need for the course project
## and rename data
data <- data[, grep("mean|std|ID|Activity", names(data))]
## We can (but not required )rearrange the data by ID using dplyr package
if(!require(dplyr)){
install.packages("dplyr")
}
library(dplyr)
data <- arrange(data, ID)
## The tricky part is how to creates an independent tidy data set
## with the "average of each variable for each activity and each subject
## The simplest way is to melt the data to form a long data frame
## with column ID, Activity, + other column names as the variable
## The we use dcast to obtain the data frame along with calculating the
## average we want
datamelt <- melt(data, id = c("ID", "Activity"),
measure.vars = names(data)[-(1:2)])
tidy_data <- dcast(datamelt, ID + Activity ~ variable, mean)
write.table(tidy_data, file = "./tidy_data.txt")
q()
